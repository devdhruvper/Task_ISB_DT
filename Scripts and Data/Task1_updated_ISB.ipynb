{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXCz2sYN7wyE5Ml1ptlV+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devdhruvper/Task_ISB_DT/blob/master/Scripts%20and%20Data/Task1_updated_ISB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "peVewxTq2iF0"
      },
      "outputs": [],
      "source": [
        "#Task1 - Dhruv Talan\n",
        "#defining the function we will need to convert our date into the following fromat of dd-mm-yyy\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_suitably(data_str):\n",
        " date_obj = datetime.strptime(data_str, \"%d/%m/%Y\")\n",
        " new_date_str = date_obj.strftime(\"%d-%m-%Y\")\n",
        " return new_date_str"
      ],
      "metadata": {
        "id": "2isxfMTB6sPg"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_final_list=[]\n",
        "for year in range(2008,2024):\n",
        "\n",
        "    URL = f'https://www.teaboard.gov.in/WEEKLYPRICES/{year}'\n",
        "    response = requests.get(URL)\n",
        "    Soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    tables = Soup.find_all('table')\n",
        "    second_table = tables[1]\n",
        "\n",
        "    # I obsereved that second table is the table whose data needs to be collected\n",
        "    tr_first = second_table.find('tr')\n",
        "    th = tr_first.find_all('b')\n",
        "    c_n = []\n",
        "    for col_name in th:\n",
        "        c_n.append(col_name.text)\n",
        "\n",
        "    # Getting the header names of the table using the first <tr> element and the header cells in it\n",
        "\n",
        "    df = pd.DataFrame(columns=c_n)\n",
        "    lencn = len(c_n)  # no of columns\n",
        "\n",
        "    tr_all = second_table.find_all('tr')\n",
        "    relevant_tr = tr_all[1:]\n",
        "\n",
        "    cell = []\n",
        "    for tr in relevant_tr:\n",
        "        for row in tr.find_all('td'):\n",
        "            for data in row.find_all('span'):\n",
        "                cell.append(data.text)\n",
        "\n",
        "    lencell = len(cell)  # represnts total no of cells in the table\n",
        "\n",
        "    rows = [cell[i:i + lencn] for i in range(0, lencell, lencn)]\n",
        "\n",
        "\n",
        "    r = pd.DataFrame(rows, columns=df.columns)\n",
        "    df=pd.concat([df,r],ignore_index=True)\n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "    df=df.drop(columns=['Tea Serve'],axis=0)\n",
        "    df=pd.melt(df,id_vars=['Week Ending/Date'],var_name=\"location\",value_name=\"average_price\")\n",
        "    df.rename(columns={'Week Ending/Date':'week'},inplace=True)\n",
        "    data_final_list.append(df)\n",
        "df_final_tables = pd.concat(data_final_list)\n",
        "df_final_tables.reset_index(drop=True, inplace=True)#making datframe\n",
        "print(df_final_tables) #the complete dataframe for all years\n",
        "df_final_tables['week']=df_final_tables['week'].apply(convert_suitably) #applying the function to entire column\n",
        "df_final_tables.to_csv('Data of WEEKLY AVERAGE PRICES OF TOTAL TEA SOLD AT INDIAN AUCTION 2008-2023.csv',index=False) #converting it to csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1lF84AT2mDT",
        "outputId": "b1a454df-a0ae-440e-c1d7-5151d7da7e4b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            week    location   average_price\n",
            "0     26/08/2008     Kolkata  176.74(166.83)\n",
            "1     19/08/2008     Kolkata  179.36(171.08)\n",
            "2     27/12/2008     Kolkata   101.19(85.17)\n",
            "3     20/12/2008     Kolkata   102.69(85.00)\n",
            "4     13/12/2008     Kolkata   103.91(83.16)\n",
            "...          ...         ...             ...\n",
            "6467  04/02/2023  Coimbatore  130.73(112.97)\n",
            "6468  28/01/2023  Coimbatore  127.44(110.06)\n",
            "6469  21/01/2023  Coimbatore  127.67(108.97)\n",
            "6470  14/01/2023  Coimbatore  121.28(112.49)\n",
            "6471  07/01/2023  Coimbatore  121.27(112.37)\n",
            "\n",
            "[6472 rows x 3 columns]\n"
          ]
        }
      ]
    }
  ]
}